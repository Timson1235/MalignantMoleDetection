{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9e6490",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:28.916027Z",
     "iopub.status.busy": "2025-02-05T21:51:28.915646Z",
     "iopub.status.idle": "2025-02-05T21:51:28.921101Z",
     "shell.execute_reply": "2025-02-05T21:51:28.920149Z"
    },
    "papermill": {
     "duration": 0.01114,
     "end_time": "2025-02-05T21:51:28.922629",
     "exception": false,
     "start_time": "2025-02-05T21:51:28.911489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07845bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:28.928943Z",
     "iopub.status.busy": "2025-02-05T21:51:28.928714Z",
     "iopub.status.idle": "2025-02-05T21:51:46.751339Z",
     "shell.execute_reply": "2025-02-05T21:51:46.750580Z"
    },
    "papermill": {
     "duration": 17.827554,
     "end_time": "2025-02-05T21:51:46.753148",
     "exception": false,
     "start_time": "2025-02-05T21:51:28.925594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch  \n",
    "import numpy as np  \n",
    "from PIL import Image  # For loading images  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461e8416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:46.759545Z",
     "iopub.status.busy": "2025-02-05T21:51:46.759153Z",
     "iopub.status.idle": "2025-02-05T21:51:49.872554Z",
     "shell.execute_reply": "2025-02-05T21:51:49.871441Z"
    },
    "papermill": {
     "duration": 3.118148,
     "end_time": "2025-02-05T21:51:49.874208",
     "exception": false,
     "start_time": "2025-02-05T21:51:46.756060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ResNet50 weights from: /kaggle/input/testmodel2/pytorch/default/1/resnet50.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d9e1dcd1a318>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resnet_weights_path, map_location=torch.device('cpu'))\n",
      "<ipython-input-3-d9e1dcd1a318>:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mole_model.load_state_dict(torch.load('/kaggle/input/mole_cnn/pytorch/default/1/mole_cnn_state_dict.pth', map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoleCNN model loaded successfully from 'mole_cnn_state_dict.pth'\n"
     ]
    }
   ],
   "source": [
    "# Define the MoleCNN class\n",
    "class MoleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1, resnet_weights_path=None):  # Add resnet_weights_path argument\n",
    "        super(MoleCNN, self).__init__()\n",
    "        \n",
    "        # Load ResNet50 model without downloading pre-trained weights\n",
    "        self.resnet = models.resnet50(weights=None)\n",
    "        \n",
    "        # Load ResNet50 weights from the local file\n",
    "        if resnet_weights_path and os.path.exists(resnet_weights_path):\n",
    "            print(f\"Loading ResNet50 weights from: {resnet_weights_path}\")\n",
    "            state_dict = torch.load(resnet_weights_path, map_location=torch.device('cpu'))\n",
    "            self.resnet.load_state_dict(state_dict)\n",
    "        else:\n",
    "            print(\"No ResNet50 weights provided. Using randomly initialized weights.\")\n",
    "        \n",
    "        # Freeze all parameters in the pretrained model\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze the last layer (layer4) for fine-tuning\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Replace the final fully connected layer\n",
    "        # ResNet50's final layer has 2048 features\n",
    "        self.resnet.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Get the features from ResNet\n",
    "        x = self.resnet(x)\n",
    "        \n",
    "        # Apply sigmoid for binary classification probability\n",
    "        probability_of_class_1 = x\n",
    "        \n",
    "        return probability_of_class_1\n",
    "\n",
    "# Path to the ResNet50 weights\n",
    "resnet_weights_path = '/kaggle/input/testmodel2/pytorch/default/1/resnet50.pth'\n",
    "\n",
    "# Initialize the MoleCNN model with ResNet50 weights\n",
    "mole_model = MoleCNN(resnet_weights_path=resnet_weights_path)\n",
    "\n",
    "# Load the MoleCNN state_dict\n",
    "mole_model.load_state_dict(torch.load('/kaggle/input/mole_cnn/pytorch/default/1/mole_cnn_state_dict.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "mole_model.eval()\n",
    "\n",
    "print(\"MoleCNN model loaded successfully from 'mole_cnn_state_dict.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0747c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:49.881070Z",
     "iopub.status.busy": "2025-02-05T21:51:49.880784Z",
     "iopub.status.idle": "2025-02-05T21:51:50.273217Z",
     "shell.execute_reply": "2025-02-05T21:51:50.272131Z"
    },
    "papermill": {
     "duration": 0.39729,
     "end_time": "2025-02-05T21:51:50.274743",
     "exception": false,
     "start_time": "2025-02-05T21:51:49.877453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /kaggle/working/jpg_test_images/ISIC_0015657.jpg\n",
      "Saved: /kaggle/working/jpg_test_images/ISIC_0015729.jpg\n",
      "Saved: /kaggle/working/jpg_test_images/ISIC_0015740.jpg\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Paths\n",
    "hdf5_path = \"/kaggle/input/isic-2024-challenge/test-image.hdf5\"\n",
    "output_folder = \"/kaggle/working/jpg_test_images\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open HDF5 file\n",
    "with h5py.File(hdf5_path, \"r\") as f:\n",
    "    for isic_id in f.keys():  # Iterate over image keys\n",
    "        raw_data = f[isic_id][()]  # Read raw image data\n",
    "\n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(raw_data))  # Decode image\n",
    "            image = image.convert(\"RGB\")  # Ensure RGB format\n",
    "\n",
    "            # Save as JPG\n",
    "            save_path = os.path.join(output_folder, f\"{isic_id}.jpg\")\n",
    "            image.save(save_path, \"JPEG\")\n",
    "\n",
    "            print(f\"Saved: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {isic_id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0e95d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:50.281275Z",
     "iopub.status.busy": "2025-02-05T21:51:50.280846Z",
     "iopub.status.idle": "2025-02-05T21:51:50.286154Z",
     "shell.execute_reply": "2025-02-05T21:51:50.285304Z"
    },
    "papermill": {
     "duration": 0.009943,
     "end_time": "2025-02-05T21:51:50.287526",
     "exception": false,
     "start_time": "2025-02-05T21:51:50.277583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestMoleDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, img))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open and convert to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_path  # Return image path to track predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43bbcb78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:50.293316Z",
     "iopub.status.busy": "2025-02-05T21:51:50.293029Z",
     "iopub.status.idle": "2025-02-05T21:51:50.297749Z",
     "shell.execute_reply": "2025-02-05T21:51:50.297127Z"
    },
    "papermill": {
     "duration": 0.00887,
     "end_time": "2025-02-05T21:51:50.299004",
     "exception": false,
     "start_time": "2025-02-05T21:51:50.290134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = TestMoleDataset(image_dir=output_folder, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f20235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:50.304924Z",
     "iopub.status.busy": "2025-02-05T21:51:50.304675Z",
     "iopub.status.idle": "2025-02-05T21:51:53.890107Z",
     "shell.execute_reply": "2025-02-05T21:51:53.889112Z"
    },
    "papermill": {
     "duration": 3.590142,
     "end_time": "2025-02-05T21:51:53.891785",
     "exception": false,
     "start_time": "2025-02-05T21:51:50.301643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.110296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.347629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.057784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015740  0.110296\n",
       "1  ISIC_0015657  0.347629\n",
       "2  ISIC_0015729  0.057784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Load trained model (adjust path if needed)\n",
    "mole_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Ensure model runs on GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mole_model.to(device)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Disable gradients for inference\n",
    "with torch.no_grad():\n",
    "    for images, img_paths in test_loader:\n",
    "        images = images.to(device)\n",
    "        logits = mole_model(images)  # Model outputs logits\n",
    "\n",
    "        # Apply sigmoid to get the probability of class 1\n",
    "        probabilities = torch.sigmoid(logits).squeeze(1)  # Squeeze to remove unnecessary dimensions\n",
    "\n",
    "        # Store probabilities with image names (excluding the extension)\n",
    "        for img_path, prob in zip(img_paths, probabilities.cpu().numpy()):\n",
    "            # Extract the ISIC ID from the image path (e.g., ISIC_0015657.jpg -> ISIC_0015657)\n",
    "            isic_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            results.append({\"isic_id\": isic_id, \"target\": prob})\n",
    "\n",
    "# Convert results to DataFrame and save\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to submission.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97746f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T21:51:53.899299Z",
     "iopub.status.busy": "2025-02-05T21:51:53.898985Z",
     "iopub.status.idle": "2025-02-05T21:51:53.914374Z",
     "shell.execute_reply": "2025-02-05T21:51:53.913380Z"
    },
    "papermill": {
     "duration": 0.020919,
     "end_time": "2025-02-05T21:51:53.915950",
     "exception": false,
     "start_time": "2025-02-05T21:51:53.895031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved successfully!\n",
      "        isic_id    target\n",
      "0  ISIC_0015740  0.110296\n",
      "1  ISIC_0015657  0.347629\n",
      "2  ISIC_0015729  0.057784\n",
      "Deleted file: /kaggle/working/__notebook__.ipynb\n",
      "Deleted folder: /kaggle/working/jpg_test_images\n",
      "Cleanup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "file_path = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"✅ Submission file saved successfully!\")\n",
    "\n",
    "    # Display first few rows\n",
    "    df_check = pd.read_csv(file_path)\n",
    "    print(df_check.head())\n",
    "else:\n",
    "    print(\"❌ Submission file NOT found. Check the file path.\")\n",
    "\n",
    "# Cleanup: Remove all files and directories except submission.csv\n",
    "working_dir = \"/kaggle/working/\"\n",
    "file_to_keep = \"submission.csv\"\n",
    "\n",
    "# List all files and folders in the directory\n",
    "items = os.listdir(working_dir)\n",
    "\n",
    "# Iterate through all items\n",
    "for item in items:\n",
    "    item_path = os.path.join(working_dir, item)\n",
    "\n",
    "    # Remove files other than submission.csv\n",
    "    if os.path.isfile(item_path) and item != file_to_keep:\n",
    "        os.remove(item_path)\n",
    "        print(f\"Deleted file: {item_path}\")\n",
    "\n",
    "    # Remove any directories\n",
    "    elif os.path.isdir(item_path):\n",
    "        shutil.rmtree(item_path)\n",
    "        print(f\"Deleted folder: {item_path}\")\n",
    "\n",
    "print(\"Cleanup complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "sourceId": 220840191,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 234579,
     "modelInstanceId": 212939,
     "sourceId": 249119,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 236327,
     "modelInstanceId": 214644,
     "sourceId": 251088,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.323493,
   "end_time": "2025-02-05T21:51:57.415302",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T21:51:25.091809",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
