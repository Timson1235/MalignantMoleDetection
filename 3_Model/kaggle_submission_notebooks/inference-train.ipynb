{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":250703,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":214297,"modelId":235969},{"sourceId":250721,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":214315,"modelId":235988}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:24:31.405947Z","iopub.execute_input":"2025-02-05T16:24:31.406325Z","iopub.status.idle":"2025-02-05T16:24:31.409686Z","shell.execute_reply.started":"2025-02-05T16:24:31.406303Z","shell.execute_reply":"2025-02-05T16:24:31.408904Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport os\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch  \nimport numpy as np  \nfrom PIL import Image  # For loading images  \n\nclass MoleCNN(nn.Module):\n    def __init__(self, num_classes=1, pretrained_weights_path=None):\n        super(MoleCNN, self).__init__()\n        \n        # Load ResNet model without downloading\n        self.resnet = models.resnet50(weights=None)\n        \n        # If a path to pre-downloaded weights is provided, load them\n        if pretrained_weights_path and os.path.exists(pretrained_weights_path):\n            state_dict = torch.load(pretrained_weights_path)\n            self.resnet.load_state_dict(state_dict)\n        \n        # Freeze all parameters in the pretrained model\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n        \n        for param in self.resnet.layer4.parameters():\n            param.requires_grad = True\n        \n        # Replace the final fully connected layer\n        self.resnet.fc = nn.Linear(2048, num_classes)\n        \n    def forward(self, x):\n        # Get the features from ResNet\n        x = self.resnet(x)\n        \n        return x\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:58:07.504816Z","iopub.execute_input":"2025-02-05T16:58:07.505112Z","iopub.status.idle":"2025-02-05T16:58:07.511913Z","shell.execute_reply.started":"2025-02-05T16:58:07.505088Z","shell.execute_reply":"2025-02-05T16:58:07.510806Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mole_model = MoleCNN()\nmole_model.load_state_dict(torch.load('/kaggle/input/workingmodel/pytorch/default/1/mole_model_state_dict.pth', map_location=torch.device('cpu')))\nmole_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:24:31.410570Z","iopub.execute_input":"2025-02-05T16:24:31.410868Z","iopub.status.idle":"2025-02-05T16:24:33.432755Z","shell.execute_reply.started":"2025-02-05T16:24:31.410839Z","shell.execute_reply":"2025-02-05T16:24:33.431926Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-3-7870409c943a>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  mole_model.load_state_dict(torch.load('/kaggle/input/workingmodel/pytorch/default/1/mole_model_state_dict.pth', map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"MoleCNN(\n  (resnet): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=1, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Define the TestMoleDataset class\nclass TestMoleDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.images = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, img))]\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert(\"RGB\")  # Open and convert to RGB\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, img_path  # Return image path to track predictions\n\n# Define the transformation for inference\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Create the dataset and dataloader\ntest_dataset = TestMoleDataset(image_dir=\"/kaggle/input/isic-2024-challenge/train-image/image\", transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:24:33.433483Z","iopub.execute_input":"2025-02-05T16:24:33.433707Z","iopub.status.idle":"2025-02-05T16:45:20.970209Z","shell.execute_reply.started":"2025-02-05T16:24:33.433688Z","shell.execute_reply":"2025-02-05T16:45:20.969269Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from PIL import Image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:56:59.363285Z","iopub.execute_input":"2025-02-05T16:56:59.363608Z","iopub.status.idle":"2025-02-05T16:56:59.368005Z","shell.execute_reply.started":"2025-02-05T16:56:59.363577Z","shell.execute_reply":"2025-02-05T16:56:59.367175Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Specify the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load your trained model and move to device\nmodel = MoleCNN(num_classes=1)  # Replace with your actual model class\nmodel.load_state_dict(torch.load(\"/kaggle/input/workingmodel/pytorch/default/1/mole_model_state_dict.pth\"))\nmodel = model.to(device)  # Move model to device\nmodel.eval()  # Set the model to evaluation mode\n\n# Perform inference\npredictions = []\nimage_paths = []\nwith torch.no_grad():  # Disable gradient computation\n    for images, paths in test_loader:\n        images = images.to(device)  # Move images to the same device as the model\n        outputs = model(images)  # Forward pass\n        probabilities = torch.sigmoid(outputs)  # Apply sigmoid for binary classification\n        predictions.extend(probabilities.cpu().numpy())  # Move back to CPU for saving\n        image_paths.extend(paths)  # Save corresponding image paths\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T16:58:11.209649Z","iopub.execute_input":"2025-02-05T16:58:11.209974Z","iopub.status.idle":"2025-02-05T17:14:20.620113Z","shell.execute_reply.started":"2025-02-05T16:58:11.209947Z","shell.execute_reply":"2025-02-05T17:14:20.619108Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-9-50907c02cc99>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/workingmodel/pytorch/default/1/mole_model_state_dict.pth\"))\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Extract ISIC ID from image path\nisic_ids = [os.path.basename(path).split(\".\")[0] for path in image_paths]\n\n# Create a DataFrame in the correct format\nresults = pd.DataFrame({\n    \"isic_id\": isic_ids,\n    \"target\": [float(pred) for pred in predictions]  # Ensure float conversion\n})\n\n# Save to CSV\nresults.to_csv(\"/kaggle/working/train_predictions.csv\", index=False)\nprint(\"Inference completed and predictions saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:14:22.295190Z","iopub.execute_input":"2025-02-05T17:14:22.295484Z","iopub.status.idle":"2025-02-05T17:14:23.647916Z","shell.execute_reply.started":"2025-02-05T17:14:22.295462Z","shell.execute_reply":"2025-02-05T17:14:23.646939Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-11-d3d186014169>:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  \"target\": [float(pred) for pred in predictions]  # Ensure float conversion\n","output_type":"stream"},{"name":"stdout","text":"Inference completed and predictions saved!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"results.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T17:15:29.287584Z","iopub.execute_input":"2025-02-05T17:15:29.287910Z","iopub.status.idle":"2025-02-05T17:15:29.307108Z","shell.execute_reply.started":"2025-02-05T17:15:29.287881Z","shell.execute_reply":"2025-02-05T17:15:29.306311Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        isic_id    target\n0  ISIC_9730802  0.438136\n1  ISIC_2834883  0.412724\n2  ISIC_5115027  0.448499\n3  ISIC_3264822  0.399724\n4  ISIC_1950204  0.463720","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_9730802</td>\n      <td>0.438136</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_2834883</td>\n      <td>0.412724</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_5115027</td>\n      <td>0.448499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_3264822</td>\n      <td>0.399724</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_1950204</td>\n      <td>0.463720</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12}]}